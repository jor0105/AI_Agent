"""
Testes de integra√ß√£o para AIAgent com providers reais (OpenAI e Ollama).

Este m√≥dulo testa o AIAgent em cen√°rios da vida real, incluindo:
- Inicializa√ß√£o com diferentes configura√ß√µes
- Chat com IAs reais
- Tratamento de erros
- M√©tricas e hist√≥rico
- Valida√ß√µes de entrada
"""

import os

import pytest

from src.domain.exceptions import InvalidAgentConfigException
from src.presentation.agent_controller import AIAgent

# ============================================================================
# CONFIGURA√á√ïES GLOBAIS - IAs para testes
# ============================================================================

# Modelos Ollama (devem estar instalados localmente)
IA_OLLAMA_TEST: str = "phi4-mini:latest"

# Modelos OpenAI (requerem API key v√°lida)
IA_OPENAI_TEST_1: str = "gpt-5-mini"
IA_OPENAI_TEST_2: str = "gpt-5-nano"


# ============================================================================
# HELPERS
# ============================================================================


def _get_openai_api_key():
    """Helper para obter a chave da API do OpenAI do ambiente (.env) ou pular o teste."""
    from src.infra.adapters.OpenAI.client_openai import ClientOpenAI
    from src.infra.config.environment import EnvironmentConfig

    # Evitar executar chamadas reais em ambientes de CI por padr√£o
    if os.getenv("CI"):
        pytest.skip("Skipping real API integration test on CI (set CI=0 to run)")

    try:
        # Usa EnvironmentConfig que carrega do .env automaticamente
        api_key = EnvironmentConfig.get_api_key(ClientOpenAI.API_OPENAI_NAME)
        return api_key
    except EnvironmentError:
        pytest.skip(
            f"Skipping integration test: {ClientOpenAI.API_OPENAI_NAME} not found in .env file"
        )


def _check_ollama_available():
    """Helper para verificar se o Ollama est√° dispon√≠vel e rodando."""
    import subprocess

    # Evitar executar chamadas reais em ambientes de CI por padr√£o
    if os.getenv("CI"):
        pytest.skip("Skipping real Ollama integration test on CI (set CI=0 to run)")

    try:
        # Tenta verificar se o Ollama est√° rodando
        result = subprocess.run(["ollama", "list"], capture_output=True, timeout=5)
        if result.returncode != 0:
            pytest.skip("Ollama n√£o est√° dispon√≠vel ou n√£o est√° rodando")
    except (FileNotFoundError, subprocess.TimeoutExpired):
        pytest.skip("Ollama n√£o est√° instalado ou n√£o est√° respondendo")


def _check_ollama_model_available(model: str):
    """Helper para verificar se um modelo espec√≠fico est√° dispon√≠vel no Ollama."""
    import subprocess

    try:
        result = subprocess.run(
            ["ollama", "list"], capture_output=True, text=True, timeout=5
        )
        if model not in result.stdout:
            pytest.skip(
                f"Modelo {model} n√£o est√° dispon√≠vel no Ollama. Execute: ollama pull {model}"
            )
    except Exception as e:
        pytest.skip(f"N√£o foi poss√≠vel verificar modelos dispon√≠veis: {e}")


# ============================================================================
# TESTES DE INICIALIZA√á√ÉO - ERROS
# ============================================================================


@pytest.mark.integration
class TestAIAgentInitializationErrors:
    def test_initialization_with_empty_model_raises_error(self):
        with pytest.raises(InvalidAgentConfigException):
            AIAgent(
                provider="openai",
                model="",
                name="Test Agent",
                instructions="Be helpful",
            )

    def test_initialization_with_empty_name_raises_error(self):
        """Testa que name vazio (quando fornecido) lan√ßa InvalidAgentConfigException."""
        with pytest.raises(InvalidAgentConfigException):
            AIAgent(
                provider="openai",
                model="gpt-5-mini",
                name="",
                instructions="Be helpful",
            )

    def test_initialization_with_empty_instructions_raises_error(self):
        """Testa que instructions vazio (quando fornecido) lan√ßa InvalidAgentConfigException."""
        with pytest.raises(InvalidAgentConfigException):
            AIAgent(
                provider="openai",
                model="gpt-5-mini",
                name="Test Agent",
                instructions="",
            )

    def test_initialization_with_none_name(self):
        """Testa que name=None √© aceito."""
        agent = AIAgent(
            provider="openai",
            model="gpt-5-mini",
            name=None,
            instructions="Be helpful",
        )
        configs = agent.get_configs()
        assert configs["name"] is None

    def test_initialization_with_none_instructions(self):
        """Testa que instructions=None √© aceito."""
        agent = AIAgent(
            provider="openai",
            model="gpt-5-mini",
            name="Test Agent",
            instructions=None,
        )
        configs = agent.get_configs()
        assert configs["instructions"] is None

    def test_initialization_with_both_none(self):
        """Testa que name e instructions podem ser None ao mesmo tempo."""
        agent = AIAgent(
            provider="openai",
            model="gpt-5-mini",
            name=None,
            instructions=None,
        )
        configs = agent.get_configs()
        assert configs["name"] is None
        assert configs["instructions"] is None

    def test_initialization_with_only_required_fields(self):
        """Testa cria√ß√£o apenas com campos obrigat√≥rios."""
        agent = AIAgent(
            provider="openai",
            model="gpt-5-mini",
        )
        configs = agent.get_configs()
        assert configs["provider"] == "openai"
        assert configs["model"] == "gpt-5-mini"
        assert configs["name"] is None
        assert configs["instructions"] is None

    def test_initialization_with_invalid_provider_raises_error(self):
        """Testa que provider inv√°lido lan√ßa exce√ß√£o."""
        with pytest.raises(
            Exception
        ):  # Pode ser ValueError ou InvalidAgentConfigException
            AIAgent(
                provider="invalid_provider_xyz",
                model="gpt-5-mini",
                name="Test Agent",
                instructions="Be helpful",
            )

    def test_initialization_with_zero_history_max_size_raises_error(self):
        """Testa que history_max_size zero lan√ßa InvalidAgentConfigException."""
        with pytest.raises(InvalidAgentConfigException, match="history_max_size"):
            AIAgent(
                provider="openai",
                model="gpt-5-mini",
                name="Test Agent",
                instructions="Be helpful",
                history_max_size=0,
            )

    def test_initialization_with_negative_history_max_size_raises_error(self):
        """Testa que history_max_size negativo lan√ßa InvalidAgentConfigException."""
        with pytest.raises(InvalidAgentConfigException, match="history_max_size"):
            AIAgent(
                provider="openai",
                model="gpt-5-mini",
                name="Test Agent",
                instructions="Be helpful",
                history_max_size=-5,
            )


# ============================================================================
# TESTES DE INICIALIZA√á√ÉO - SUCESSO COM OPENAI
# ============================================================================


@pytest.mark.integration
class TestAIAgentInitializationSuccessOpenAI:
    """Testes de sucesso na inicializa√ß√£o do AIAgent com OpenAI."""

    def test_initialization_with_openai_gpt4_mini(self):
        """Testa inicializa√ß√£o bem-sucedida com OpenAI GPT-4 Mini."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Test Agent OpenAI",
            instructions="You are a helpful assistant",
        )

        assert agent is not None
        configs = agent.get_configs()
        assert configs["provider"] == "openai"
        assert configs["model"] == IA_OPENAI_TEST_1
        assert configs["name"] == "Test Agent OpenAI"

    def test_initialization_with_openai_gpt4_nano(self):
        """Testa inicializa√ß√£o bem-sucedida com OpenAI GPT-4 Nano."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_2,
            name="Test Agent Nano",
            instructions="You are a helpful assistant",
        )

        assert agent is not None
        configs = agent.get_configs()
        assert configs["provider"] == "openai"
        assert configs["model"] == IA_OPENAI_TEST_2

    def test_initialization_with_custom_config_openai(self):
        """Testa inicializa√ß√£o com configura√ß√µes customizadas no OpenAI."""
        _get_openai_api_key()

        custom_config = {
            "temperature": 0.7,
            "max_tokens": 500,
            "top_p": 0.9,
        }

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Custom Config Agent",
            instructions="Be creative",
            config=custom_config,
        )

        configs = agent.get_configs()
        assert configs["config"] == custom_config

    def test_initialization_with_custom_history_size_openai(self):
        """Testa inicializa√ß√£o com tamanho de hist√≥rico customizado."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Large History Agent",
            instructions="Remember our conversation",
            history_max_size=50,
        )

        configs = agent.get_configs()
        assert configs["history_max_size"] == 50


# ============================================================================
# TESTES DE INICIALIZA√á√ÉO - SUCESSO COM OLLAMA
# ============================================================================


@pytest.mark.integration
class TestAIAgentInitializationSuccessOllama:
    """Testes de sucesso na inicializa√ß√£o do AIAgent com Ollama."""

    def test_initialization_with_ollama_phi4(self):
        """Testa inicializa√ß√£o bem-sucedida com Ollama Phi-4 Mini."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Test Agent Ollama",
            instructions="You are a helpful assistant",
        )

        assert agent is not None
        configs = agent.get_configs()
        assert configs["provider"] == "ollama"
        assert configs["model"] == IA_OLLAMA_TEST
        assert configs["name"] == "Test Agent Ollama"

    def test_initialization_with_custom_config_ollama(self):
        """Testa inicializa√ß√£o com configura√ß√µes customizadas no Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        custom_config = {
            "temperature": 0.5,
            "num_predict": 100,
        }

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Custom Config Ollama",
            instructions="Be precise",
            config=custom_config,
        )

        configs = agent.get_configs()
        assert configs["config"] == custom_config

    def test_initialization_with_custom_history_size_ollama(self):
        """Testa inicializa√ß√£o com tamanho de hist√≥rico customizado no Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Small History Agent",
            instructions="Keep context",
            history_max_size=5,
        )

        configs = agent.get_configs()
        assert configs["history_max_size"] == 5


# ============================================================================
# TESTES DE CHAT - OPENAI
# ============================================================================


@pytest.mark.integration
class TestAIAgentChatOpenAI:
    """Testes de chat com OpenAI."""

    def test_simple_chat_with_openai(self):
        """Testa chat simples com OpenAI."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Chat Agent",
            instructions="You are a helpful assistant. Answer briefly.",
        )

        response = agent.chat("What is 2+2?")

        assert response is not None
        assert isinstance(response, str)
        assert len(response) > 0
        assert "4" in response

    def test_multiple_chats_with_history_openai(self):
        """Testa m√∫ltiplas conversas mantendo hist√≥rico."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="History Agent",
            instructions="You are a helpful assistant. Remember the context.",
        )

        # Primeira mensagem
        response1 = agent.chat("My name is Jordan")
        assert response1 is not None

        # Segunda mensagem referenciando a primeira
        response2 = agent.chat("What is my name?")
        assert response2 is not None
        assert "Jordan" in response2 or "jordan" in response2.lower()

    def test_chat_with_empty_message_openai(self):
        """Testa que mensagem vazia pode causar erro ou resposta padr√£o."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Empty Test Agent",
            instructions="Answer any question",
        )

        # Dependendo da implementa√ß√£o, pode lan√ßar erro ou retornar resposta
        try:
            response = agent.chat("")
            # Se n√£o lan√ßar erro, deve retornar uma string
            assert isinstance(response, str)
        except Exception:
            # √â aceit√°vel que lance erro com mensagem vazia
            pass

    def test_chat_with_long_message_openai(self):
        """Testa chat com mensagem longa."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Long Message Agent",
            instructions="Summarize the text briefly.",
        )

        long_message = "This is a test. " * 100
        response = agent.chat(long_message)

        assert response is not None
        assert isinstance(response, str)
        assert len(response) > 0

    def test_chat_with_unicode_openai(self):
        """Testa chat com caracteres Unicode."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Unicode Agent",
            instructions="You are a multilingual assistant.",
        )

        response = agent.chat("Ol√°! Como voc√™ est√°? ‰Ω†Â•Ω üåç")

        assert response is not None
        assert isinstance(response, str)
        assert len(response) > 0


# ============================================================================
# TESTES DE CHAT - OLLAMA
# ============================================================================


@pytest.mark.integration
class TestAIAgentChatOllama:
    """Testes de chat com Ollama."""

    def test_simple_chat_with_ollama(self):
        """Testa chat simples com Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Chat Ollama Agent",
            instructions="You are a helpful assistant. Answer briefly.",
        )

        response = agent.chat("What is 2+2?")

        assert response is not None
        assert isinstance(response, str)
        assert len(response) > 0

    def test_multiple_chats_with_history_ollama(self):
        """Testa m√∫ltiplas conversas mantendo hist√≥rico."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="History Ollama Agent",
            instructions="You are a helpful assistant. Remember the context.",
        )

        # Primeira mensagem
        response1 = agent.chat("My favorite color is blue")
        assert response1 is not None

        # Segunda mensagem referenciando a primeira
        response2 = agent.chat("What is my favorite color?")
        assert response2 is not None
        # Verifica se lembra do contexto
        assert "blue" in response2.lower()

    def test_chat_with_unicode_ollama(self):
        """Testa chat com caracteres Unicode no Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Unicode Ollama Agent",
            instructions="You are a multilingual assistant.",
        )

        response = agent.chat("Ol√°! üåç")

        assert response is not None
        assert isinstance(response, str)
        assert len(response) > 0


# ============================================================================
# TESTES DE HIST√ìRICO
# ============================================================================


@pytest.mark.integration
class TestAIAgentHistory:
    """Testes de gerenciamento de hist√≥rico."""

    def test_clear_history_openai(self):
        """Testa limpeza de hist√≥rico com OpenAI."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Clear History Agent",
            instructions="Remember our conversation.",
        )

        # Faz um chat
        agent.chat("My name is Jordan")

        # Verifica que h√° hist√≥rico
        configs = agent.get_configs()
        assert len(configs["history"]) > 0

        # Limpa hist√≥rico
        agent.clear_history()

        # Verifica que hist√≥rico foi limpo
        configs = agent.get_configs()
        assert len(configs["history"]) == 0

    def test_clear_history_ollama(self):
        """Testa limpeza de hist√≥rico com Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Clear History Ollama",
            instructions="Remember context.",
        )

        # Faz um chat
        agent.chat("Hello")

        # Verifica que h√° hist√≥rico
        configs = agent.get_configs()
        assert len(configs["history"]) > 0

        # Limpa hist√≥rico
        agent.clear_history()

        # Verifica que hist√≥rico foi limpo
        configs = agent.get_configs()
        assert len(configs["history"]) == 0

    def test_history_max_size_enforcement_openai(self):
        """Testa que o tamanho m√°ximo do hist√≥rico √© respeitado."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Small History Agent",
            instructions="Chat briefly.",
            history_max_size=2,  # Apenas 2 mensagens (1 user + 1 assistant)
        )

        # Faz 3 chats (6 mensagens no total)
        agent.chat("First message")
        agent.chat("Second message")
        agent.chat("Third message")

        # Verifica que apenas as √∫ltimas mensagens est√£o no hist√≥rico
        configs = agent.get_configs()
        # Com max_size=2, deve ter no m√°ximo 2 mensagens
        assert len(configs["history"]) <= 2


# ============================================================================
# TESTES DE M√âTRICAS
# ============================================================================


@pytest.mark.integration
class TestAIAgentMetrics:
    """Testes de coleta de m√©tricas."""

    def test_get_metrics_after_chat_openai(self):
        """Testa coleta de m√©tricas ap√≥s chat com OpenAI."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Metrics Agent",
            instructions="Answer briefly.",
        )

        # Faz um chat
        agent.chat("Hello")

        # Obt√©m m√©tricas
        metrics = agent.get_metrics()

        assert metrics is not None
        assert isinstance(metrics, list)
        assert len(metrics) > 0

        # Verifica estrutura da m√©trica
        first_metric = metrics[0]
        assert hasattr(first_metric, "model")
        assert hasattr(first_metric, "latency_ms")
        assert first_metric.latency_ms > 0

    def test_get_metrics_after_multiple_chats_openai(self):
        """Testa ac√∫mulo de m√©tricas ap√≥s m√∫ltiplos chats."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Multi Metrics Agent",
            instructions="Answer briefly.",
        )

        # Faz 3 chats
        agent.chat("First")
        agent.chat("Second")
        agent.chat("Third")

        # Obt√©m m√©tricas
        metrics = agent.get_metrics()

        assert len(metrics) >= 3

    def test_export_metrics_json_openai(self):
        """Testa exporta√ß√£o de m√©tricas em JSON."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="JSON Metrics Agent",
            instructions="Answer briefly.",
        )

        # Faz um chat
        agent.chat("Test")

        # Exporta m√©tricas
        json_str = agent.export_metrics_json()

        assert json_str is not None
        assert isinstance(json_str, str)
        assert "summary" in json_str
        assert "metrics" in json_str

    def test_export_metrics_prometheus_openai(self):
        """Testa exporta√ß√£o de m√©tricas em formato Prometheus."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Prom Metrics Agent",
            instructions="Answer briefly.",
        )

        # Faz um chat
        agent.chat("Test")

        # Exporta m√©tricas
        prom_str = agent.export_metrics_prometheus()

        assert prom_str is not None
        assert isinstance(prom_str, str)
        assert "chat_requests_total" in prom_str

    def test_get_metrics_after_chat_ollama(self):
        """Testa coleta de m√©tricas ap√≥s chat com Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Metrics Ollama Agent",
            instructions="Answer briefly.",
        )

        # Faz um chat
        agent.chat("Hello")

        # Obt√©m m√©tricas
        metrics = agent.get_metrics()

        assert metrics is not None
        assert isinstance(metrics, list)
        assert len(metrics) > 0


# ============================================================================
# TESTES DE GET_CONFIGS
# ============================================================================


@pytest.mark.integration
class TestAIAgentGetConfigs:
    """Testes do m√©todo get_configs."""

    def test_get_configs_returns_all_fields_openai(self):
        """Testa que get_configs retorna todos os campos esperados."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Config Test Agent",
            instructions="Test instructions",
            config={"temperature": 0.7},
            history_max_size=15,
        )

        configs = agent.get_configs()

        assert "provider" in configs
        assert "model" in configs
        assert "name" in configs
        assert "instructions" in configs
        assert "config" in configs
        assert "history" in configs
        assert "history_max_size" in configs

        assert configs["provider"] == "openai"
        assert configs["model"] == IA_OPENAI_TEST_1
        assert configs["name"] == "Config Test Agent"
        assert configs["history_max_size"] == 15

    def test_get_configs_returns_all_fields_ollama(self):
        """Testa que get_configs retorna todos os campos esperados com Ollama."""
        _check_ollama_available()
        _check_ollama_model_available(IA_OLLAMA_TEST)

        agent = AIAgent(
            provider="ollama",
            model=IA_OLLAMA_TEST,
            name="Config Ollama Agent",
            instructions="Test ollama",
            config={"temperature": 0.5},
            history_max_size=20,
        )

        configs = agent.get_configs()

        assert configs["provider"] == "ollama"
        assert configs["model"] == IA_OLLAMA_TEST
        assert configs["history_max_size"] == 20


# ============================================================================
# TESTES DE EDGE CASES E CEN√ÅRIOS ESPECIAIS
# ============================================================================


@pytest.mark.integration
class TestAIAgentEdgeCases:
    """Testes de casos extremos e especiais."""

    def test_agent_with_very_long_instructions_openai(self):
        """Testa agente com instru√ß√µes muito longas."""
        _get_openai_api_key()

        long_instructions = "You are a helpful assistant. " * 100

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Long Instructions Agent",
            instructions=long_instructions,
        )

        response = agent.chat("Hello")

        assert response is not None
        assert isinstance(response, str)

    def test_agent_with_special_characters_in_name(self):
        """Testa agente com caracteres especiais no nome."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Agent-Test_123!@#",
            instructions="Be helpful",
        )

        configs = agent.get_configs()
        assert configs["name"] == "Agent-Test_123!@#"

    def test_chat_after_clear_history_openai(self):
        """Testa que √© poss√≠vel fazer chat ap√≥s limpar hist√≥rico."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Clear and Chat Agent",
            instructions="Remember context",
        )

        # Primeiro chat
        response1 = agent.chat("My name is Alice")
        assert response1 is not None

        # Limpa hist√≥rico
        agent.clear_history()

        # Segundo chat (n√£o deve lembrar o primeiro)
        response2 = agent.chat("What is my name?")
        assert response2 is not None
        # N√£o deve mencionar Alice, pois o hist√≥rico foi limpo

    def test_multiple_agents_same_model_independent(self):
        """Testa que m√∫ltiplos agentes com o mesmo modelo s√£o independentes."""
        _get_openai_api_key()

        agent1 = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Agent 1",
            instructions="You are agent 1",
        )

        agent2 = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_1,
            name="Agent 2",
            instructions="You are agent 2",
        )

        # Faz chat com agent1
        agent1.chat("Hello from agent 1")

        # Verifica que agent2 n√£o tem o hist√≥rico de agent1
        configs2 = agent2.get_configs()
        assert len(configs2["history"]) == 0

    def test_agent_with_minimal_config(self):
        """Testa agente com configura√ß√£o m√≠nima (apenas campos obrigat√≥rios)."""
        _get_openai_api_key()

        agent = AIAgent(
            provider="openai",
            model=IA_OPENAI_TEST_2,
            name="Minimal Agent",
            instructions="Be helpful",
        )

        # Deve funcionar normalmente
        response = agent.chat("Hi")
        assert response is not None

        configs = agent.get_configs()
        assert configs["history_max_size"] == 10  # Valor padr√£o
        assert configs["config"] == {}  # Config padr√£o vazio
